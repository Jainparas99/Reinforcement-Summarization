{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T19:51:27.656409Z",
     "iopub.status.busy": "2024-12-11T19:51:27.656207Z",
     "iopub.status.idle": "2024-12-11T20:06:32.325206Z",
     "shell.execute_reply": "2024-12-11T20:06:32.324122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset loaded from ./tokenized_cnn_dailymail\n",
      "Model and tokenizer loaded from ./new_model\n"
     ]
    }
   ],
   "source": [
    "#from data_preprocessing import load_and_preprocess_data\n",
    "from train_model import train_model\n",
    "from evaluate import evaluate_model\n",
    "from datasets import load_from_disk\n",
    "#from rl_training import train_rl_model, load_rl_model\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "import os\n",
    "\n",
    "# Step 1: Load the tokenized dataset\n",
    "tokenized_dataset_path = \"./tokenized_cnn_dailymail\"\n",
    "try:\n",
    "    tokenized_dataset = load_from_disk(tokenized_dataset_path)\n",
    "    print(f\"Tokenized dataset loaded from {tokenized_dataset_path}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Tokenized dataset not found at {tokenized_dataset_path}. Please preprocess and save it first.\")\n",
    "\n",
    "# Step 2: Load or train the baseline model\n",
    "model_path = \"./new_model\"\n",
    "try:\n",
    "    # Load saved model and tokenizer\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    print(f\"Model and tokenizer loaded from {model_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model not found at {model_path}. Training a new model...\")\n",
    "    train_model(tokenized_dataset, save_path=model_path)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.26934525322955366, recall=0.3602463636274879, fmeasure=0.30252468927069914), mid=Score(precision=0.292423662285552, recall=0.3929663421342301, fmeasure=0.32776543372953215), high=Score(precision=0.3184325315090215, recall=0.42668200910643056, fmeasure=0.3536614759198495)), 'rouge2': AggregateScore(low=Score(precision=0.09900605421032654, recall=0.13524754457649948, fmeasure=0.11275603792166371), mid=Score(precision=0.11758541720820494, recall=0.15903963535058496, fmeasure=0.13168541717958604), high=Score(precision=0.13653515139547978, recall=0.18476744871069717, fmeasure=0.15236039352410796)), 'rougeL': AggregateScore(low=Score(precision=0.19423215875411667, recall=0.2635538315183025, fmeasure=0.21964526695982453), mid=Score(precision=0.21495479349538615, recall=0.2905431752390082, fmeasure=0.24146084611729618), high=Score(precision=0.23709780285043489, recall=0.3213960980307847, fmeasure=0.26478044820838914)), 'rougeLsum': AggregateScore(low=Score(precision=0.2224117007954609, recall=0.2989812556134314, fmeasure=0.25077132486948644), mid=Score(precision=0.2465111736696859, recall=0.32944170227129665, fmeasure=0.27566756568920303), high=Score(precision=0.2710764558872505, recall=0.36194533628331815, fmeasure=0.3019633339913386))}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline model\n",
    "results = evaluate_model(tokenized_dataset[\"test\"], \"./new_model\")\n",
    "print(\"Baseline ROUGE Scores:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:06:32.329908Z",
     "iopub.status.busy": "2024-12-11T20:06:32.329734Z",
     "iopub.status.idle": "2024-12-11T23:39:46.371751Z",
     "shell.execute_reply": "2024-12-11T23:39:46.370845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL-Tuned ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.25100072075438085, recall=0.1993977160383028, fmeasure=0.21338175322955663), mid=Score(precision=0.25870779131176025, recall=0.20582763351843764, fmeasure=0.21975229117655812), high=Score(precision=0.26725030615436635, recall=0.21107152086299955, fmeasure=0.225336784409068)), 'rouge2': AggregateScore(low=Score(precision=0.05862306760884156, recall=0.0487416399903649, fmeasure=0.0510952569346142), mid=Score(precision=0.06325483974222897, recall=0.05234511810320749, fmeasure=0.05505311891697022), high=Score(precision=0.06780703311311573, recall=0.05586013673835154, fmeasure=0.05879574176006237)), 'rougeL': AggregateScore(low=Score(precision=0.20315960285073092, recall=0.1635369764552097, fmeasure=0.17397414865516192), mid=Score(precision=0.20963625260587723, recall=0.167852087071973, fmeasure=0.1784693516718131), high=Score(precision=0.21577249684188582, recall=0.17279658829993275, fmeasure=0.18340527590378947)), 'rougeLsum': AggregateScore(low=Score(precision=0.2273009863304348, recall=0.1816143277790984, fmeasure=0.19407961047240596), mid=Score(precision=0.23435769412940277, recall=0.1868232960477118, fmeasure=0.1993504544368498), high=Score(precision=0.24180307435230705, recall=0.19225240267163324, fmeasure=0.2044789276158725))}\n"
     ]
    }
   ],
   "source": [
    "results_custom = evaluate_model(tokenized_dataset[\"test\"], \"./t5_rl_summarization_model\")\n",
    "print(\"RL-Tuned ROUGE Scores:\", results_custom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idai610",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
